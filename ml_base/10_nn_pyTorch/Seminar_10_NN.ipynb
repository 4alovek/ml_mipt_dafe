{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Py3 research env",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUF68Fc70QVm"
      },
      "source": [
        "# Семинар 10 - Нейросети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2k0b73c-H6W"
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-28T00:59:42.103233Z",
          "start_time": "2020-02-28T00:59:42.099338Z"
        },
        "id": "bX7WKpm20QVp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "# warnings.simplefilter('ignore')\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb0b0s_tw0ft"
      },
      "source": [
        "## 1 Вспомним PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F-2IcFB0QVu"
      },
      "source": [
        "Нахождение сложной производной\n",
        "\n",
        "Найдите производную по x от функции\n",
        "$$\\sin\\left(\\tan(x)\\frac{x^2}{y} + \\ln(e^{-x^2 + 3}+x^3y)\\right)\\tan(x^2e^{x^9})$$\n",
        "\n",
        "При этом надо пользоваться встроенным в PyTorch autograd. Численное вычисление производной может не дать нужный результат."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-02-28T00:13:20.890514Z",
          "start_time": "2020-02-28T00:13:20.639022Z"
        },
        "id": "dicy-gHI0QVu"
      },
      "source": [
        "def find_x_derivative(x, y):\n",
        "    # Ваш код здесь\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDUuuezl4Ant"
      },
      "source": [
        "find_x_derivative(1,21)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4WixrwoouOI"
      },
      "source": [
        "## 2 Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### В семинаре, будем использовать набор данных `fashion_mnist`, загрузим их"
      ],
      "metadata": {
        "id": "zFXUhoLdsB8B"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "817LGj2touOJ"
      },
      "source": [
        "from torchvision import datasets,transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1yTnOKlouON"
      },
      "source": [
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = True, download=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y_gHUUaouOQ"
      },
      "source": [
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', train = False, download = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-yhD9MIouOT"
      },
      "source": [
        "num_classes = len(trainset.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwATUm42gW3I"
      },
      "source": [
        "trainset.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw3moMZ4ouOW"
      },
      "source": [
        "x_train = trainset.train_data\n",
        "y_train = trainset.train_labels\n",
        "\n",
        "x_test = testset.train_data\n",
        "y_test = testset.train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BOoVSZBouOZ"
      },
      "source": [
        "fig = plt.figure(figsize=(15,5))\n",
        "for i in range(num_classes):\n",
        "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "    idx = np.where(y_train[:]==i)[0]\n",
        "    features_idx = x_train[idx,::]\n",
        "    img_num = np.random.randint(features_idx.shape[0])\n",
        "    im = features_idx[img_num]\n",
        "    ax.set_title(trainset.classes[i])\n",
        "    plt.imshow(im, cmap='gray_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEwx6Wp4ouOc"
      },
      "source": [
        "### Проведем небольшие предобработки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1swzXaqouOc"
      },
      "source": [
        "x_train_flat = x_train.flatten(start_dim=1).float()\n",
        "x_test_flat = x_test.flatten(start_dim=1).float()\n",
        "print(f'Была размерность: {x_train.shape}, стала: {x_train_flat.shape}')\n",
        "print(f'Была размерность: {x_test.shape}, стала: {x_test_flat.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eXoS2gMouOf"
      },
      "source": [
        "D_out = num_classes\n",
        "D_in = x_train_flat.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZYEiMQ3DpVB"
      },
      "source": [
        "## 3 Определим архитектуру нейросети в pyTorch\n",
        "\n",
        "(вариантов определения архитектуры много, но эти 2 варианта наиболее популярные)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9C-YR6PGouOh"
      },
      "source": [
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, 128),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(128, 10),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(10, D_out),\n",
        "    torch.nn.Softmax(dim=1)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Uv5d7YFouOp"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(D_in, 128)\n",
        "        self.act1 = torch.nn.Sigmoid()\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "        self.act2 = torch.nn.Sigmoid()\n",
        "        self.fc3 = torch.nn.Linear(10, D_out)\n",
        "        self.act3 = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act3(x)\n",
        "        return x\n",
        "\n",
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL0biu-EouOr"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1JmI-2fouOu"
      },
      "source": [
        "# Forward pass: compute predicted y by passing x to the model. Module objects\n",
        "# override the __call__ operator so you can call them like functions. When\n",
        "# doing so you pass a Tensor of input data to the Module and it produces\n",
        "# a Tensor of output data.\n",
        "y_pred = model(x_train_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJtuDQ6sjvea"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5JD6xWqouOw"
      },
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWHhi6hTiVOB"
      },
      "source": [
        "# Compute and print loss. We pass Tensors containing the predicted and true\n",
        "# values of y, and the loss function returns a Tensor containing the\n",
        "# loss.\n",
        "loss_old = loss_fn(y_pred, y_train)\n",
        "loss_old"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK5o-0gNihzV"
      },
      "source": [
        "acc_old = accuracy_score(y_train.numpy(), y_pred.argmax(dim=1))\n",
        "acc_old"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM8oRGwlih2f"
      },
      "source": [
        "# Zero the gradients before running the backward pass.\n",
        "model.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DqxPMqRih5L"
      },
      "source": [
        "# Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "# parameters of the model. Internally, the parameters of each Module are stored\n",
        "# in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "# all learnable parameters in the model.\n",
        "loss_old.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loqaoy8Zi1PH"
      },
      "source": [
        "learning_rate = 1e-2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1fPGyDKiw-U"
      },
      "source": [
        "# Update the weights using gradient descent. Each parameter is a Tensor, so\n",
        "# we can access its gradients like we did before.\n",
        "with torch.no_grad():\n",
        "  # Ваш код здесь\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSIGz0wnixBE"
      },
      "source": [
        "y_pred = model(x_train_flat.float())\n",
        "loss_new = loss_fn(y_pred, y_train)\n",
        "step = loss_new.item()-loss_old.item()\n",
        "\n",
        "acc_new = accuracy_score(y_train, y_pred.argmax(dim=1))\n",
        "\n",
        "print(f'Лосс: {loss_old.item()} -> {loss_new.item()}. Step {step} ')\n",
        "print(f'Accuracy: {acc_old} -> {acc_new}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFGhystlouO1"
      },
      "source": [
        "def batch_train(model, loss_fn, learning_rate, x, y):\n",
        "  # Ваш код здесь\n",
        "\n",
        "    return(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG1SImTaouO3"
      },
      "source": [
        "def train(model, n_epochs, batch_size, learning_rate,  X, y, X_test, y_test):\n",
        "    acc_train_all = []\n",
        "    loss_train_all = []\n",
        "    acc_test_all = []\n",
        "    loss_test_all = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        permutation = torch.randperm(X.size()[0])\n",
        "\n",
        "        for i in tqdm(range(0,X.float().size()[0], batch_size)):\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch_x, batch_y = X[indices], y[indices]\n",
        "            batch_train(model, loss_fn, learning_rate, batch_x, batch_y)\n",
        "\n",
        "        y_test_pred = model(X_test)\n",
        "        y_train_pred = model(X)\n",
        "\n",
        "\n",
        "        acc_train = accuracy_score(y, y_train_pred.argmax(dim=1))\n",
        "        loss_train = loss_fn(y_train_pred, y).detach()\n",
        "        acc_test = accuracy_score(y_test, y_test_pred.argmax(dim=1))\n",
        "        loss_test = loss_fn(y_test_pred, y_test).detach()\n",
        "\n",
        "        acc_train_all = np.append(acc_train_all, acc_train)\n",
        "        loss_train_all = np.append(loss_train_all, loss_train)\n",
        "        acc_test_all = np.append(acc_test_all, acc_test)\n",
        "        loss_test_all = np.append(loss_test_all, loss_test)\n",
        "\n",
        "\n",
        "        print(f'Epoch {epoch}: \\n Accuracy - train: {acc_train} | test: {acc_test} \\n Loss - train: {loss_train} | test: {loss_test}')\n",
        "\n",
        "    return(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tvQm6qs8ouO6"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000\n",
        "learning_rate = 1\n",
        "model = Model()\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = \\\n",
        "          train(model, n_epochs, batch_size, learning_rate, x_train_flat, y_train, x_test_flat, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUytpKIuouO9"
      },
      "source": [
        "def vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all):\n",
        "    fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "\n",
        "    plt.plot(loss_train_all, label='loss')\n",
        "    plt.plot(loss_test_all, label='val_loss')\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(acc_train_all, label='acc')\n",
        "    plt.plot(acc_test_all, label='val_acc')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rchVUmigouO_"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdDt8drzouPE"
      },
      "source": [
        "## 4 Что мы можем улучшить?\n",
        "- Отнормировать признаки\n",
        "- Задать правила инициации весов\n",
        "- Выбрать функцию активации\n",
        "- Настроить скорость обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZWTYU3xouPE"
      },
      "source": [
        "### 4.1 Нормировка\n",
        "![picture](https://drive.google.com/uc?export=view&id=1kSw5ceu5iexG5DIPkhHGtXUepZtl9t6Q)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelNorm(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelNorm, self).__init__()\n",
        "        self.act1 = torch.nn.Sigmoid()\n",
        "        self.fc1 = torch.nn.Linear(D_in, 128)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(10)\n",
        "        self.fc3 = torch.nn.Linear(10, D_out)\n",
        "        self.act2 = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act2(x)\n",
        "        return x\n",
        "\n",
        "model_norm = ModelNorm()"
      ],
      "metadata": {
        "id": "-D5UHislr4HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDCj3aJBouPF"
      },
      "source": [
        "mean = x_train_flat.mean()\n",
        "std = x_train_flat.std()\n",
        "\n",
        "x_train_norm = (x_train_flat - mean) / std\n",
        "x_test_norm = (x_test_flat - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkqCvSZzouPJ"
      },
      "source": [
        "x_train_norm.max(), x_train_norm.min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8efS67TuNmA"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000\n",
        "learning_rate = 1\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model_norm, n_epochs, batch_size, learning_rate,\n",
        "                                                                   x_train_norm, y_train, x_test_norm, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm1OG8zyuNmC"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo3z_0ojqYaN"
      },
      "source": [
        "### 4.2 Функции активации\n",
        "![picture](https://drive.google.com/uc?export=view&id=1pHhpRQNXHnFCyVyvJJJtqMkLhJInT1i3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL5kSrl7wGT-"
      },
      "source": [
        "class ModelReLU(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelReLU, self).__init__()\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.fc1 = torch.nn.Linear(D_in, 128)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
        "        self.fc2 = torch.nn.Linear(128, 10)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(10)\n",
        "        self.fc3 = torch.nn.Linear(10, D_out)\n",
        "        self.act2 = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act2(x)\n",
        "        return x\n",
        "\n",
        "model_relu = ModelReLU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVgMmIa0wGUD"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000\n",
        "learning_rate = 1\n",
        "\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model_relu, n_epochs, batch_size, learning_rate, x_train_norm, y_train, x_test_norm, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Mezplo7wGUH"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4BICv8uouPM"
      },
      "source": [
        "### 4.3 [Инициациия весов](https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/)\n",
        "__Случайно__  \n",
        "$ w = a * random$, но тогда если $a \\gg 1$, то на выходе $b\\gg1$ и если $a \\ll 1 $, то $b \\approx 0 $  \n",
        "\n",
        "__Xavier__  \n",
        "$a = \\frac{1}{\\sqrt{n}}$, где $n$ - кол-во нейронов на входе\n",
        "\n",
        "__He__  \n",
        "$a = \\frac{1}{\\sqrt{\\frac{n}{2}}}$, где $n$ - кол-во нейронов на входе"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XswYTN_LouPM"
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == torch.nn.Linear:\n",
        "        torch.nn.init.kaiming_normal_(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ4-dwjOouPO"
      },
      "source": [
        "Примените к модели  функцию инициации весов с помощью метода .apply()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be7BL4lqIahs"
      },
      "source": [
        "model_relu = ModelReLU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aPFssk4ouPP"
      },
      "source": [
        "model_he = model_relu.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcBd7Ot3ouPR"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000\n",
        "learning_rate = 1\n",
        "\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model_he, n_epochs, batch_size, learning_rate,\n",
        "                                                                   x_train_norm, y_train, x_test_norm, y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GnH4Sj6ouPT"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUS8D8PdouPe"
      },
      "source": [
        "### 4.4 Влияние метода оптимизации градиентного спуска"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSPLQfCrouPe"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1D3hA1C9MCx5eNRHb2yo2W_4wJjT0IjHv)\n",
        "\n",
        "**Momentum**\n",
        "\n",
        "Вместо того, чтобы использовать только градиент текущего шага, мы будем накапливать импульс градиента прошлых шагов для определения направления движения.\n",
        "В связи со стохастической природой, обновления градиента происходят \"зигзагообразно\", с помощью момента мы усиливаем движение вдоль основного направления. На практике коэффициент у момента инициализируется на уровне 0,5 и постепенно увеличивается до 0,9 в течение нескольких эпох.\n",
        "  \n",
        "**RMSProp** (Root Mean Square Propogation)   \n",
        "\n",
        "Мы обновляяем меньше веса, которые слишком часто обновляются, и будем использовать усреднённый по истории квадрат градиента.\n",
        "\n",
        "**Adam** (Adaptive moment estimation)\n",
        "\n",
        "Cочетает в себе и идею накопления движения и идею более слабого обновления весов для типичных признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Update batch train"
      ],
      "metadata": {
        "id": "UeZNsbc8DCpG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1WqtKJouPh"
      },
      "source": [
        "def batch_train(model, optimizer, x, y):\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    #    with torch.no_grad():\n",
        "    #    for param in model.parameters():\n",
        "    #        param -= learning_rate * param.grad\n",
        "    optimizer.step()\n",
        "    return (loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare models"
      ],
      "metadata": {
        "id": "fSwkCFvNDVL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu = ModelReLU()\n",
        "model_he_SGD = model_relu.apply(init_weights)"
      ],
      "metadata": {
        "id": "eqxjE2MBDXTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu = ModelReLU()\n",
        "model_he_Momentum = model_relu.apply(init_weights)"
      ],
      "metadata": {
        "id": "dKCYT_k0DjZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu = ModelReLU()\n",
        "model_he_Adam = model_relu.apply(init_weights)"
      ],
      "metadata": {
        "id": "RZwTimzDDjcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare optimizers"
      ],
      "metadata": {
        "id": "SGlQF6QNDIDr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiNYQh0fouPe"
      },
      "source": [
        "optimizerSGD = torch.optim.SGD(model_he_SGD.parameters(), lr=0.01, momentum=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizerMomentum = torch.optim.SGD(model_he_Momentum.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "QGBGQLx-DLTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizerAdam = torch.optim.Adam(model_he_Adam.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "hhsdruqUDLWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "ygKUF5dZErqk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "l1nZ_qEQouPj"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000\n",
        "\n",
        "\n",
        "loss_test_sgd = []\n",
        "loss_test_sgd_moment = []\n",
        "loss_test_adam = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    permutation = torch.randperm(x_train_norm.size()[0])\n",
        "\n",
        "    for i in tqdm(range(0,x_train_norm.float().size()[0], batch_size)):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = x_train_norm[indices], y_train[indices]\n",
        "        batch_train(model_he_SGD, optimizerSGD, batch_x, batch_y)\n",
        "        batch_train(model_he_Momentum, optimizerMomentum, batch_x, batch_y)\n",
        "        batch_train(model_he_Adam, optimizerAdam, batch_x, batch_y)\n",
        "\n",
        "    y_test_pred = model_he_SGD(x_test_norm)\n",
        "    loss_train = loss_fn(y_test_pred, y_test).detach().numpy()\n",
        "    print(f' SGD Epoch: {epoch} loss {loss_train}')\n",
        "    loss_test_sgd.append(loss_train)\n",
        "\n",
        "    y_test_pred = model_he_Momentum(x_test_norm)\n",
        "    loss_train = loss_fn(y_test_pred, y_test).detach().numpy()\n",
        "    print(f' Momentum Epoch: {epoch} loss {loss_train}')\n",
        "    loss_test_sgd_moment.append(loss_train)\n",
        "\n",
        "    y_test_pred = model_he_Adam(x_test_norm)\n",
        "    loss_train = loss_fn(y_test_pred, y_test).detach().numpy()\n",
        "    print(f' Adam Epoch: {epoch} loss {loss_train}')\n",
        "    loss_test_adam.append(loss_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN6ZsupyouPm"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "plt.plot(loss_test_sgd, label='SGD')\n",
        "plt.plot(loss_test_sgd_moment, label='SGD with momentum')\n",
        "plt.plot(loss_test_adam, label='Adam')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA9GBCWtouPW"
      },
      "source": [
        "### 4.5 Влияние скорости обучения\n",
        "Посмотрим, как влияет параметр `learning_rate` на качество нашей модели на обучающей выборке"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_relu = ModelReLU()\n",
        "model_he_Adam = model_relu.apply(init_weights)"
      ],
      "metadata": {
        "id": "Gdic06-GIdKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizerAdam = torch.optim.Adam(model_he_Adam.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "-Xjy5SIYIgzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "scheduler = lr_scheduler.LinearLR(optimizerAdam, start_factor=1.0, end_factor=0.01, total_iters=10)"
      ],
      "metadata": {
        "id": "cdnAz8odIYLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, scheduler, n_epochs, batch_size,  X, y, X_test, y_test):\n",
        "    acc_train_all = []\n",
        "    loss_train_all = []\n",
        "    acc_test_all = []\n",
        "    loss_test_all = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        permutation = torch.randperm(X.size()[0])\n",
        "\n",
        "        for i in tqdm(range(0,X.float().size()[0], batch_size)):\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch_x, batch_y = X[indices], y[indices]\n",
        "            batch_train(model, optimizer, batch_x, batch_y)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        y_test_pred = model(X_test)\n",
        "        y_train_pred = model(X)\n",
        "\n",
        "\n",
        "        acc_train = accuracy_score(y, y_train_pred.argmax(dim=1))\n",
        "        loss_train = loss_fn(y_train_pred, y).detach()\n",
        "        acc_test = accuracy_score(y_test, y_test_pred.argmax(dim=1))\n",
        "        loss_test = loss_fn(y_test_pred, y_test).detach()\n",
        "\n",
        "        acc_train_all = np.append(acc_train_all, acc_train)\n",
        "        loss_train_all = np.append(loss_train_all, loss_train)\n",
        "        acc_test_all = np.append(acc_test_all, acc_test)\n",
        "        loss_test_all = np.append(loss_test_all, loss_test)\n",
        "\n",
        "\n",
        "        print(f'Epoch {epoch}: \\n Accuracy - train: {acc_train} | test: {acc_test} \\n Loss - train: {loss_train} | test: {loss_test}')\n",
        "\n",
        "    return(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "metadata": {
        "id": "mywM8rbdKOJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP8QSOGDouPZ"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 1000\n",
        "\n",
        "acc_train_all, loss_train_all, acc_test_all, loss_test_all = train(model_he_Adam, optimizerAdam, scheduler, n_epochs, batch_size,\n",
        "                                                                    x_train_norm, y_train, x_test_norm, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uw84G_DouPb"
      },
      "source": [
        "vis_history(acc_train_all, loss_train_all, acc_test_all, loss_test_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKGry9LYouPo"
      },
      "source": [
        "# Ссылки\n",
        "- Материалы курса [dlschool](https://www.dlschool.org/)\n",
        "- [Курс \"Deep learning на пальцах\", лекция 4](https://youtu.be/tnrbx7V9RbA)\n",
        "- [Статья: Оптимизация градиентного спуска](http://ruder.io/optimizing-gradient-descent/)\n",
        "- [Статья: Методы оптимизации нейронных сетей](https://habr.com/ru/post/318970/)\n",
        "- YSDA [Practical RL course week04 materials](https://github.com/yandexdataschool/Practical_RL/tree/master/week04_%5Brecap%5D_deep_learning).\n",
        "- PyTorch official tutorials and [this kaggle kernel](https://www.kaggle.com/pinocookie/pytorch-dataset-and-dataloader)\n",
        "- PyTorch tutorial by [Stanford CS 231n course](http://cs231n.stanford.edu)"
      ]
    }
  ]
}